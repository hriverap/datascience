{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magister en Ciencia de Datos - UDD\n",
    "## DBAnalytics (Ciencia de Datos aplicada)\n",
    "**Sprint 2: Datos transformados II**\n",
    "\n",
    "En base a las funciones RFM del Sprint 1, crear nuevos features para cada variable en el dataset user_logs.csv y transactions.csv (sólo si aplica).\n",
    "Crear nuevas funciones para construir features tales como:\n",
    "Tendencias de actividad del msno entre diferentes rangos de tiempo usando diferentes variables, usando variables del dataset user_logs.csv\n",
    "Métricas de la actividad del msno usando diferentes variables del dataset transactions.csv \n",
    "En base a las funciones implementadas (y otras definidas por cada grupo), se deben implementar al menos 300 features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lectura de archivos desde repositorio y contatenacion con nuevas versiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://kk_data_udd/day_listen.csv#1564861559107461\n",
      "gs://kk_data_udd/df_test.csv#1565240427109815\n",
      "gs://kk_data_udd/df_train.csv#1565240406697715\n",
      "gs://kk_data_udd/members_v3.csv#1563566790239785\n",
      "gs://kk_data_udd/sample_submission_v2.csv#1563580288727022\n",
      "gs://kk_data_udd/sample_submission_zero.csv#1563580145138161\n",
      "gs://kk_data_udd/sub_age_xgb_pred.csv#1565055727433942\n",
      "gs://kk_data_udd/sub_day_listen.csv#1564861658307683\n",
      "gs://kk_data_udd/sub_reg_via_xgb_pred.csv#1565055581900599\n",
      "gs://kk_data_udd/sub_user_satisfaction.cvs#1564861608790636\n",
      "gs://kk_data_udd/test_sorted_v1.csv#1565242819914404\n",
      "gs://kk_data_udd/train.csv#1563565831541482\n",
      "gs://kk_data_udd/train_sorted_v1.csv#1565243444686022\n",
      "gs://kk_data_udd/train_v2.csv#1563580263806878\n",
      "gs://kk_data_udd/transactions.csv#1563580088583483\n",
      "gs://kk_data_udd/transactions_v2.csv#1563580288931202\n",
      "gs://kk_data_udd/user_label_201702.csv#1563681052454642\n",
      "gs://kk_data_udd/user_label_201703.csv#1563681061521361\n",
      "gs://kk_data_udd/user_latent_satisfaction.csv#1564861506322352\n",
      "gs://kk_data_udd/user_logs.csv#1563642063874891\n",
      "gs://kk_data_udd/user_logs_v2.csv#1563580748443816\n",
      "gs://kk_data_udd/submission/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -a gs://kk_data_udd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('gs://kk_data_udd/train.csv')\n",
    "df_train = pd.concat((df_train, pd.read_csv('gs://kk_data_udd/train_v2.csv')), axis=0, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('gs://kk_data_udd/sample_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members = pd.read_csv('gs://kk_data_udd/members_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = pd.read_csv('gs://kk_data_udd/transactions.csv')\n",
    "df_transactions = pd.concat((df_transactions, pd.read_csv('gs://kk_data_udd/transactions_v2.csv')), axis=0, ignore_index=True).reset_index(drop=True)\n",
    "df_transactions = df_transactions.sort_values(by=['transaction_date'], ascending=[False]).reset_index(drop=True)\n",
    "df_transactions = df_transactions.drop_duplicates(subset=['msno'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions['discount'] = df_transactions['plan_list_price'] - df_transactions['actual_amount_paid']\n",
    "df_transactions['is_discount'] = df_transactions.discount.apply(lambda x: 1 if x > 0 else 0)\n",
    "df_transactions['membership_days'] = pd.to_datetime(df_transactions['membership_expire_date']).subtract(pd.to_datetime(df_transactions['transaction_date'])).dt.days.astype(np.int16)\n",
    "df_transactions['amt_per_day'] = df_transactions['actual_amount_paid'] / df_transactions['payment_plan_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['marker'] = 1\n",
    "df_test['marker'] = 0\n",
    "df_combined = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merging Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_combined, df_members, how='left', on='msno')\n",
    "df_members = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalizamos genero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = {'male':1, 'female':2}\n",
    "df_combined['gender'] = df_combined['gender'].map(gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merging Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_combined, df_transactions, how='left', on='msno')\n",
    "df_transactions =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separamos entramiento y test, luego eliminamos el flag \"marker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_combined[df_combined['marker'] == 1]\n",
    "df_test = df_combined[df_combined['marker']  == 0]\n",
    "\n",
    "del df_train[\"marker\"]\n",
    "del df_test[\"marker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_combined\n",
    "gc.collect()\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extraemos los registros finales de log de usuario y los contatenamos con train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq rm -f 'kk-churn:DATASET.user_log_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery \n",
    "create table `kk-churn.DATASET.user_log_features` as\n",
    "select msno, count(msno) as msno_nro, max(date) as date_last, \n",
    "sum(num_25) as num_25_sum, min(num_25) as num_25_min, max(num_25) as num_25_max, avg(num_25) as num_25_avg, stddev(num_25) as num_25_std,\n",
    "sum(num_50) as num_50_sum, min(num_50) as num_50_min, max(num_50) as num_50_max, avg(num_50) as num_50_avg, stddev(num_50) as num_50_std,\n",
    "sum(num_75) as num_75_sum, min(num_75) as num_75_min, max(num_75) as num_75_max, avg(num_75) as num_75_avg, stddev(num_75) as num_75_std,\n",
    "sum(num_985) as num_98_sum, min(num_985) as num_98_min, max(num_985) as num_98_max, avg(num_985) as num_98_avg, stddev(num_985) as num_98_std,\n",
    "sum(num_100) as num_100_sum, min(num_100) as num_100_min, max(num_100) as num_100_max, avg(num_100) as num_100_avg, stddev(num_100) as num_100_std,\n",
    "sum(num_unq) as num_unq_sum, min(num_unq) as num_unq_min, max(num_unq) as num_unq_max, avg(num_unq) as num_unq_avg, stddev(num_unq) as num_unq_std,\n",
    "sum(total_secs) as total_secs_sum, min(total_secs) as total_secs_min, max(total_secs) as total_secs_max, avg(total_secs) as total_secs_avg, stddev(total_secs) as total_secs_std\n",
    "from `kk-churn.DATASET.user_logs` group by msno "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "select count(*) from `kk-churn.DATASET.user_log_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query = \"\"\" \n",
    "select * from `kk-churn.DATASET.user_log_features`\n",
    "        \"\"\"\n",
    "df = pd.read_gbq(query,project_id='kk-churn',dialect='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df, how='left', on='msno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, df, how='left', on='msno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.rename(columns = {'date_last':'user_log_date'})\n",
    "df_test = df_test.rename(columns = {'date_last':'user_log_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_time(df, time_cols):\n",
    "    for time_col in time_cols:\n",
    "        df[time_col] = pd.to_datetime(df[time_col], errors = 'coerce', format = '%Y%m%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = fix_time(df_train, time_cols = ['transaction_date', 'membership_expire_date', 'registration_init_time', 'user_log_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['transaction_date', 'membership_expire_date', 'registration_init_time', 'user_log_date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = fix_time(df_test, time_cols = ['transaction_date', 'membership_expire_date', 'registration_init_time', 'user_log_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separamos las fechas en dias y meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dict = {'t_':'transaction_date', 'm_':'membership_expire_date', 'r_':'registration_init_time', 'l_':'user_log_date'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in date_dict:\n",
    "    df_train[m+'month'] = [d.month for d in df_train[date_dict[m]]]\n",
    "    df_train[m+'day'] = [d.day for d in df_train[date_dict[m]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['t_year'] = [d.year  for d in df_train['transaction_date']]\n",
    "df_train['m_year'] = [d.year for d in df_train['membership_expire_date']]\n",
    "df_train['r_year'] = [d.year for d in df_train['registration_init_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['l_year'] = [d.year for d in df_train['user_log_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in date_dict:\n",
    "        df_test[m+'month'] = [d.month for d in df_test[date_dict[m]]]\n",
    "        df_test[m+'day'] = [d.day for d in df_test[date_dict[m]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['t_year'] = [d.year for d in df_test['transaction_date']]\n",
    "df_test['m_year'] = [d.year for d in df_test['membership_expire_date']]\n",
    "df_test['r_year'] = [d.year for d in df_test['registration_init_time']]\n",
    "df_test['l_year'] = [d.year for d in df_test['user_log_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['autorenew_&_not_cancel'] = ((df_train.is_auto_renew == 1) == (df_train.is_cancel == 0)).astype(np.int8)\n",
    "df_test['autorenew_&_not_cancel'] = ((df_test.is_auto_renew == 1) == (df_test.is_cancel == 0)).astype(np.int8)\n",
    "df_train['notAutorenew_&_cancel'] = ((df_train.is_auto_renew == 0) == (df_train.is_cancel == 1)).astype(np.int8)\n",
    "df_test['notAutorenew_&_cancel'] = ((df_test.is_auto_renew == 0) == (df_test.is_cancel == 1)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Guardamos archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -a gs://kk_data_udd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('gs://kk_data_udd/test_sorted_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('gs://kk_data_udd/train_sorted_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_logs = pd.read_csv('gs://kk_data_udd/user_logs.csv')\n",
    "df_train = pd.read_csv('gs://kk_data_udd/train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
